{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2255937,"sourceType":"datasetVersion","datasetId":1357458}],"dockerImageVersionId":30145,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###### Data Visualization\nVisualize Kitti - LIDAR data\n\nGithub Repository: https://github.com/hailanyi/3D-Detection-Tracking-Viewer","metadata":{}},{"cell_type":"markdown","source":"# Dataset Functions\nFunctions to load LIDAR data","metadata":{}},{"cell_type":"markdown","source":"## Base Functions","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Function to read calibration file\n# Input: Calibration Text File Path\n# Output: P2: 3D camera coordinates to 2D image pixels\n# Output: vtc_mat: 3D Lidar coordinates to 3D camera coordinates \ndef read_calib(calib_path):\n    with open(calib_path) as f:\n        for line in f.readlines():\n            if line[:2] == \"P2\":\n                P2 = re.split(\" \", line.strip())\n                P2 = np.array(P2[-12:], np.float32)\n                P2 = P2.reshape((3, 4))\n            if line[:14] == \"Tr_velo_to_cam\" or line[:11] == \"Tr_velo_cam\":\n                vtc_mat = re.split(\" \", line.strip())\n                vtc_mat = np.array(vtc_mat[-12:], np.float32)\n                vtc_mat = vtc_mat.reshape((3, 4))\n                vtc_mat = np.concatenate([vtc_mat, [[0, 0, 0, 1]]])\n            if line[:7] == \"R0_rect\" or line[:6] == \"R_rect\":\n                R0 = re.split(\" \", line.strip())\n                R0 = np.array(R0[-9:], np.float32)\n                R0 = R0.reshape((3, 3))\n                R0 = np.concatenate([R0, [[0], [0], [0]]], -1)\n                R0 = np.concatenate([R0, [[0, 0, 0, 1]]])\n    vtc_mat = np.matmul(R0, vtc_mat)\n    return (P2, vtc_mat)\n\n# Function to read lidar data\n# Input: Path to lidar bin file\n# Input: Camera 3D to Camera 2D Matrix\n# Input: Lidar 3D to Camera 3D Matrix\n# Output: Valid points in Lidar Coordinates\ndef read_velodyne(path, P, vtc_mat, IfReduce=True):\n    max_row = 374  # y\n    max_col = 1241  # x\n    lidar = np.fromfile(path, dtype=np.float32).reshape((-1, 4))\n\n    if not IfReduce:\n        return lidar\n\n    mask = lidar[:, 0] > 0\n    lidar = lidar[mask]\n    lidar_copy = np.zeros(shape=lidar.shape)\n    lidar_copy[:, :] = lidar[:, :]\n\n    velo_tocam = vtc_mat\n    lidar[:, 3] = 1\n    lidar = np.matmul(lidar, velo_tocam.T)\n    img_pts = np.matmul(lidar, P.T)\n    velo_tocam = np.mat(velo_tocam).I\n    velo_tocam = np.array(velo_tocam)\n    normal = velo_tocam\n    normal = normal[0:3, 0:4]\n    lidar = np.matmul(lidar, normal.T)\n    lidar_copy[:, 0:3] = lidar\n    x, y = img_pts[:, 0] / img_pts[:, 2], img_pts[:, 1] / img_pts[:, 2]\n    mask = np.logical_and(np.logical_and(x >= 0, x < max_col), np.logical_and(y >= 0, y < max_row))\n\n    return lidar_copy[mask]\n\n# Function to convert 3D Camera coordinates to 3D Lidar coordinates\n# Input: 3D Camera Points\n# Input: Lidar 3D to Camera 3D Matrix\n# Output: 3D Lidar Points\n\ndef cam_to_velo(cloud,vtc_mat):\n    mat=np.ones(shape=(cloud.shape[0],4),dtype=np.float32)\n    mat[:,0:3]=cloud[:,0:3]\n    mat=np.mat(mat)\n    normal=np.mat(vtc_mat).I\n    normal=normal[0:3,0:4]\n    transformed_mat = normal * mat.T\n    T=np.array(transformed_mat.T,dtype=np.float32)\n    return T\n\n# Function to convert 3D Lidar coordinates to 3D Camera coordinates\n# Input: 3D Camera Points\n# Input: Lidar 3D to Camera 3D Matrix\n# Output: 3D Lidar Points\ndef velo_to_cam(cloud,vtc_mat):\n    mat=np.ones(shape=(cloud.shape[0],4),dtype=np.float32)\n    mat[:,0:3]=cloud[:,0:3]\n    mat=np.mat(mat)\n    normal=np.mat(vtc_mat)\n    transformed_mat = normal * mat.T\n    T=np.array(transformed_mat.T,dtype=np.float32)\n    return T\n\n# Function to read image\n# Input: Image path\n# Output: Image matrix\ndef read_image(path):\n    im=cv2.imdecode(np.fromfile(path, dtype=np.uint8), -1)\n    return im\n\n# Function to read labels\n# Input: Input label path file\n# Output: Array of Box coordinates\n# Output: Array of label names\ndef read_detection_label(path):\n\n    boxes = []\n    names = []\n\n    with open(path) as f:\n        for line in f.readlines():\n            line = line.split()\n            this_name = line[0]\n            if this_name != \"DontCare\":\n                line = np.array(line[-7:],np.float32)\n                boxes.append(line)\n                names.append(this_name)\n\n    return np.array(boxes),np.array(names)\n\n# Function to read tracking label\n# Input: Input label path file\n# Output: Frame Dictionary\n# Output: Frame Name dictionary\ndef read_tracking_label(path):\n\n    frame_dict={}\n\n    names_dict={}\n\n    with open(path) as f:\n        for line in f.readlines():\n            line = line.split()\n            this_name = line[2]\n            frame_id = int(line[0])\n            ob_id = int(line[1])\n\n            if this_name != \"DontCare\":\n                line = np.array(line[10:17],np.float32).tolist()\n                line.append(ob_id)\n\n\n                if frame_id in frame_dict.keys():\n                    frame_dict[frame_id].append(line)\n                    names_dict[frame_id].append(this_name)\n                else:\n                    frame_dict[frame_id] = [line]\n                    names_dict[frame_id] = [this_name]\n\n    return frame_dict,names_dict","metadata":{"execution":{"iopub.status.busy":"2024-03-23T20:08:01.822052Z","iopub.execute_input":"2024-03-23T20:08:01.822379Z","iopub.status.idle":"2024-03-23T20:08:01.850450Z","shell.execute_reply.started":"2024-03-23T20:08:01.822345Z","shell.execute_reply":"2024-03-23T20:08:01.849265Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Functions","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport re\nimport os\n\n# Detection Dataset Class\nclass KittiDetectionDataset:\n    # Initialization Function to read all paths\n    def __init__(self,root_path,label_path = None):\n        self.root_path = root_path\n        self.velo_path = os.path.join(self.root_path,\"velodyne\")\n        self.image_path = os.path.join(self.root_path,\"image_2\")\n        self.calib_path = os.path.join(self.root_path,\"calib\")\n        if label_path is None:\n            self.label_path = os.path.join(self.root_path, \"label_2\")\n        else:\n            self.label_path = label_path\n\n        self.all_ids = os.listdir(self.velo_path)\n\n    # Length Function\n    def __len__(self):\n        return len(self.all_ids)\n    \n    # Get index function\n    def __getitem__(self, item):\n        name = str(item).zfill(6)\n\n        velo_path = os.path.join(self.velo_path,name+'.bin')\n        image_path = os.path.join(self.image_path, name+'.png')\n        calib_path = os.path.join(self.calib_path, name+'.txt')\n        label_path = os.path.join(self.label_path, name+\".txt\")\n\n        P2,V2C = read_calib(calib_path)\n        points = read_velodyne(velo_path,P2,V2C)\n        image = read_image(image_path)\n        labels,label_names = read_detection_label(label_path)\n        labels[:,3:6] = cam_to_velo(labels[:,3:6],V2C)[:,:3]\n\n        return P2,V2C,points,image,labels,label_names","metadata":{"execution":{"iopub.status.busy":"2024-03-23T20:08:11.723715Z","iopub.execute_input":"2024-03-23T20:08:11.724000Z","iopub.status.idle":"2024-03-23T20:08:11.734903Z","shell.execute_reply.started":"2024-03-23T20:08:11.723970Z","shell.execute_reply":"2024-03-23T20:08:11.733629Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions\nUtility Functions for visualization","metadata":{}},{"cell_type":"markdown","source":"## Objects","metadata":{}},{"cell_type":"code","source":"# Download dependency\n!pip install vedo\n\n# Download object files for Cars and Ego Car\n!wget https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/car.obj\n!wget https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/ego_car.3ds\n# solve error with color_map_name not defined\n# !wget https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/color_map.py\n# !wget https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/box_op.py","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:13.514974Z","iopub.execute_input":"2024-03-23T22:02:13.515376Z","iopub.status.idle":"2024-03-23T22:02:25.293741Z","shell.execute_reply.started":"2024-03-23T22:02:13.515334Z","shell.execute_reply":"2024-03-23T22:02:25.292846Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Requirement already satisfied: vedo in /opt/conda/lib/python3.7/site-packages (2024.5.1)\nRequirement already satisfied: vtk in /opt/conda/lib/python3.7/site-packages (from vedo) (9.0.3)\nRequirement already satisfied: Pygments in /opt/conda/lib/python3.7/site-packages (from vedo) (2.10.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from vedo) (1.19.5)\nRequirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from vtk->vedo) (3.4.3)\nRequirement already satisfied: Twisted>=17.5.0 in /opt/conda/lib/python3.7/site-packages (from vtk->vedo) (21.7.0)\nRequirement already satisfied: wslink>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from vtk->vedo) (1.1.0)\nRequirement already satisfied: autobahn>=17.7.1 in /opt/conda/lib/python3.7/site-packages (from vtk->vedo) (21.3.1)\nRequirement already satisfied: txaio>=21.2.1 in /opt/conda/lib/python3.7/site-packages (from autobahn>=17.7.1->vtk->vedo) (21.2.1)\nRequirement already satisfied: cryptography>=3.4.6 in /opt/conda/lib/python3.7/site-packages (from autobahn>=17.7.1->vtk->vedo) (3.4.7)\nRequirement already satisfied: hyperlink>=21.0.0 in /opt/conda/lib/python3.7/site-packages (from autobahn>=17.7.1->vtk->vedo) (21.0.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=3.4.6->autobahn>=17.7.1->vtk->vedo) (1.14.6)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=3.4.6->autobahn>=17.7.1->vtk->vedo) (2.20)\nRequirement already satisfied: idna>=2.5 in /opt/conda/lib/python3.7/site-packages (from hyperlink>=21.0.0->autobahn>=17.7.1->vtk->vedo) (2.10)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.0.0->vtk->vedo) (8.2.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.0.0->vtk->vedo) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.0.0->vtk->vedo) (2.8.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.0.0->vtk->vedo) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.0.0->vtk->vedo) (0.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.0.0->vtk->vedo) (1.16.0)\nRequirement already satisfied: constantly>=15.1 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (15.1.0)\nRequirement already satisfied: Automat>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (20.2.0)\nRequirement already satisfied: incremental>=21.3.0 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (21.3.0)\nRequirement already satisfied: zope.interface>=4.4.2 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (5.4.0)\nRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (3.10.0.2)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from Twisted>=17.5.0->vtk->vedo) (21.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from wslink>=0.1.3->vtk->vedo) (3.7.4.post0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from zope.interface>=4.4.2->Twisted>=17.5.0->vtk->vedo) (58.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->wslink>=0.1.3->vtk->vedo) (1.6.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->wslink>=0.1.3->vtk->vedo) (5.1.0)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->wslink>=0.1.3->vtk->vedo) (3.0.1)\nRequirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->wslink>=0.1.3->vtk->vedo) (4.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n--2024-03-23 22:02:23--  https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/car.obj\nResolving github.com (github.com)... 140.82.113.4\nConnecting to github.com (github.com)|140.82.113.4|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘car.obj.6’\n\ncar.obj.6               [ <=>                ]   3.65M  --.-KB/s    in 0.1s    \n\n2024-03-23 22:02:23 (31.9 MB/s) - ‘car.obj.6’ saved [3826667]\n\n--2024-03-23 22:02:24--  https://github.com/hailanyi/3D-Detection-Tracking-Viewer/blob/master/viewer/ego_car.3ds\nResolving github.com (github.com)... 140.82.113.3\nConnecting to github.com (github.com)|140.82.113.3|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘ego_car.3ds.6’\n\nego_car.3ds.6           [ <=>                ] 144.03K  --.-KB/s    in 0.04s   \n\n2024-03-23 22:02:25 (3.66 MB/s) - ‘ego_car.3ds.6’ saved [147486]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Box Operations","metadata":{}},{"cell_type":"code","source":"# Function to convert the input box to a common type\n# Input: Input boxes\n# Output: New boxes as [x, y, z, l, w, h, yaw]\ndef convert_box_type(boxes,input_box_type = 'Kitti'):\n    boxes = np.array(boxes)\n    if len(boxes) == 0:\n        return None\n    assert  input_box_type in [\"Kitti\",\"OpenPCDet\",\"Waymo\"], 'unsupported input box type!'\n\n    if input_box_type in [\"OpenPCDet\",\"Waymo\"]:\n        return boxesdfsa\n\n    if input_box_type == \"Kitti\": #(h,w,l,x,y,z,yaw) -> (x,y,z,l,w,h,yaw)\n        boxes = np.array(boxes)\n        new_boxes = np.zeros(shape=boxes.shape)\n        new_boxes[:,:]=boxes[:,:]\n        new_boxes[:,0:3] = boxes[:,3:6]\n        new_boxes[:, 3] = boxes[:, 2]\n        new_boxes[:, 4] = boxes[:, 1]\n        new_boxes[:, 5] = boxes[:, 0]\n        new_boxes[:, 6] = (np.pi - boxes[:, 6]) + np.pi / 2\n        new_boxes[:, 2] += boxes[:, 0] / 2\n        return new_boxes\n\n# Convert box array to mesh box\n# Input: boxes array\n# Output: mesh boxes array\ndef get_mesh_boxes(boxes,colors=\"red\",\n                   mesh_alpha=0.4,\n                   ids=None,\n                   show_ids=False,\n                   box_info=None,\n                   show_box_info=False,\n                   caption_size=(0.05,0.05)):\n    vtk_boxes_list = []\n    for i in range(len(boxes)):\n        box = boxes[i]\n        angle = box[6]\n\n        new_angle = (angle / np.pi) * 180\n\n        if type(colors) is str:\n            this_c = colors\n        else:\n            this_c = colors[i]\n        vtk_box = Box(pos=(0, 0, 0), height=box[5], width=box[4], length=box[3], c=this_c, alpha=mesh_alpha)\n        vtk_box.rotateZ(new_angle)\n        vtk_box.pos(box[0], box[1], box[2])\n\n        info = \"\"\n        if ids is not None and show_ids :\n            info = \"ID: \"+str(ids[i])+'\\n'\n        if box_info is not None and show_box_info:\n            info+=str(box_info[i])\n        if info !='':\n            vtk_box.caption(info,point=(box[0],\n                            box[1]-box[4]/4, box[2]+box[5]/2),\n                            size=caption_size,\n                            alpha=1,c=this_c,\n                            font=\"Calco\",\n                            justify='left')\n            vtk_box._caption.SetBorder(False)\n            vtk_box._caption.SetLeader(False)\n\n        vtk_boxes_list.append(vtk_box)\n\n    return vtk_boxes_list\n\n# Function to get line boxes\n# Input: boxes array\n# Output: lines, arrows and spheres array\ndef get_line_boxes(boxes,\n                   colors,\n                   show_corner_spheres=True,\n                   corner_spheres_alpha=1,\n                   corner_spheres_radius=0.3,\n                   show_heading=True,\n                   heading_scale=1,\n                   show_lines=True,\n                   line_width=2,\n                   line_alpha=1,\n                   ):\n    lines_actors = []\n    sphere_actors = []\n    arraw_actors = []\n\n\n    for i in range(len(boxes)):\n        box = boxes[i]\n        corner_points = []\n        corner_points1 = []\n        corner_points2 = []\n        arraw_points1 = []\n        arraw_points2 = []\n\n        angle = box[6]\n\n        new_angle = angle\n\n        transform_mat = np.array([[np.cos(new_angle), -np.sin(new_angle), 0, box[0]],\n                                  [np.sin(new_angle), np.cos(new_angle), 0, box[1]],\n                                  [0, 0, 1, box[2]],\n                                  [0, 0, 0, 1]])\n        x = box[3]\n        y = box[4]\n        z = box[5]\n\n        corner_points.append([-x / 2, -y / 2, -z / 2, 1])\n        corner_points.append([-x / 2, -y / 2, z / 2, 1])\n        corner_points.append([-x / 2, y / 2, z / 2, 1])\n        corner_points.append([-x / 2, y / 2, -z / 2, 1])\n        corner_points.append([x / 2, y / 2, -z / 2, 1])\n        corner_points.append([x / 2, y / 2, z / 2, 1])\n        corner_points.append([x / 2, -y / 2, z / 2, 1])\n        corner_points.append([x / 2, -y / 2, -z / 2, 1])\n\n        corner_points1.append([-x / 2, -y / 2, - z / 2, 1])\n        corner_points1.append([-x / 2, -y / 2, z / 2, 1])\n        corner_points1.append([-x / 2, y / 2, z / 2, 1])\n        corner_points1.append([-x / 2, y / 2, -z / 2, 1])\n        corner_points1.append([-x / 2, y / 2, z / 2, 1])\n        corner_points1.append([-x / 2, -y / 2, z / 2, 1])\n        corner_points1.append([x / 2, -y / 2, z / 2, 1])\n        corner_points1.append([x / 2, y / 2, z / 2, 1])\n        corner_points1.append([-x / 2, -y / 2, -z / 2, 1])\n        corner_points1.append([x / 2, -y / 2, -z / 2, 1])\n        corner_points1.append([x / 2, -y / 2, z / 2, 1])\n        corner_points1.append([-x / 2, -y / 2, z / 2, 1])\n\n        corner_points2.append([x / 2, -y / 2, - z / 2, 1])\n        corner_points2.append([x / 2, -y / 2, z / 2, 1])\n        corner_points2.append([x / 2, y / 2, z / 2, 1])\n        corner_points2.append([x / 2, y / 2, -z / 2, 1])\n        corner_points2.append([-x / 2, y / 2, -z / 2, 1])\n        corner_points2.append([-x / 2, -y / 2, -z / 2, 1])\n        corner_points2.append([x / 2, -y / 2, -z / 2, 1])\n        corner_points2.append([x / 2, y / 2, -z / 2, 1])\n        corner_points2.append([-x / 2, y / 2, -z / 2, 1])\n        corner_points2.append([x / 2, y / 2, -z / 2, 1])\n        corner_points2.append([x / 2, y / 2, z / 2, 1])\n        corner_points2.append([-x / 2, y / 2, z / 2, 1])\n\n        arraw_points1.append([0, 0, 0, 1])\n        arraw_points2.append([x / 2 , 0, 0, 1])\n\n        corner_points = np.matmul(np.array(corner_points), transform_mat.T)\n        corner_points1 = np.matmul(np.array(corner_points1), transform_mat.T)\n        corner_points2 = np.matmul(np.array(corner_points2), transform_mat.T)\n        arraw_points1 = np.matmul(np.array(arraw_points1), transform_mat.T)\n        arraw_points2 = np.matmul(np.array(arraw_points2), transform_mat.T)\n\n        if type(colors) is not str:\n            this_c = colors[i]\n            corner_colors = np.tile(this_c,(corner_points.shape[0],1))\n            arraw_colors = np.tile(this_c,(arraw_points1.shape[0],1))\n\n        else:\n            this_c = colors\n            corner_colors = colors\n            arraw_colors = colors\n\n        lines = Lines(corner_points1[:, 0:3], corner_points2[:, 0:3], c=this_c, alpha=line_alpha, lw=line_width)\n\n        corner_spheres = Spheres(corner_points[:,0:3], c= corner_colors, r=corner_spheres_radius,res = 12,alpha=corner_spheres_alpha)\n\n        arraws = Arrows(arraw_points1[:,0:3],arraw_points2[:,0:3],c = arraw_colors,s=heading_scale)\n        lines_actors.append(lines)\n        sphere_actors.append(corner_spheres)\n        arraw_actors.append(arraws)\n\n    return_list =[]\n\n    if show_corner_spheres:\n        return_list+=sphere_actors\n    if show_heading:\n        return_list+=arraw_actors\n    if show_lines:\n        return_list+=lines_actors\n\n    return return_list\n\n# Function to get transformed box points\n# Input: box array\n# Output: transformed matrix\ndef get_box_points(points, pose=None):\n    PI=np.pi\n    import math\n    point=np.zeros(shape=points.shape)\n    point[:]=points[:]\n\n    h,w,l = point[5],point[4],point[3]\n    x,y,z = point[0],point[1],point[2]\n\n\n    point_num=200\n    i=1\n    label=1\n    z_vector = np.arange(- h / 2, h / 2, h / point_num)[0:point_num]\n    w_vector = np.arange(- w / 2, w / 2, w / point_num)[0:point_num]\n    l_vector = np.arange(- l / 2, l / 2, l / point_num)[0:point_num]\n\n    d_z_p = -np.sort(-np.arange(0, h / 2, h / (point_num*2))[0:point_num])\n    d_z_n = np.arange( -h / 2,0, h / (point_num*2))[0:point_num]\n\n\n    d_w_p = -np.sort(-np.arange(0, w / 2, w / (point_num*2))[0:point_num])\n    d_w_n = np.arange(-w / 2,0,  w / (point_num*2))[0:point_num]\n\n    d_l_p = np.arange(l / 2, l*(4/7) , (l*(4/7)-l / 2) / (point_num*2))[0:point_num]\n\n\n    d1 = np.zeros(shape=(point_num, 4))\n    d1[:, 0] = d_w_p\n    d1[:, 1] = d_l_p\n    d1[:, 2] = d_z_p\n    d1[:, 3] = i\n\n    d2 = np.zeros(shape=(point_num, 4))\n    d2[:, 0] = d_w_n\n    d2[:, 1] = d_l_p\n    d2[:, 2] = d_z_p\n    d2[:, 3] = i\n\n    d3 = np.zeros(shape=(point_num, 4))\n    d3[:, 0] = d_w_p\n    d3[:, 1] = d_l_p\n    d3[:, 2] = d_z_n\n    d3[:, 3] = i\n\n    d4 = np.zeros(shape=(point_num, 4))\n    d4[:, 0] = d_w_n\n    d4[:, 1] = d_l_p\n    d4[:, 2] = d_z_n\n    d4[:, 3] = i\n\n    z1 = np.zeros(shape=(point_num, 4))\n    z1[:, 0] = -w / 2\n    z1[:, 1] = -l / 2\n    z1[:, 2] = z_vector\n    z1[:, 3] = i\n    z2 = np.zeros(shape=(point_num, 4))\n    z2[:, 0] = -w / 2\n    z2[:, 1] =l / 2\n    z2[:, 2] = z_vector\n    z2[:, 3] = i\n    z3 = np.zeros(shape=(point_num, 4))\n    z3[:, 0] = w / 2\n    z3[:, 1] = -l / 2\n    z3[:, 2] = z_vector\n    z3[:, 3] = i\n    z4 = np.zeros(shape=(point_num, 4))\n    z4[:, 0] = w / 2\n    z4[:, 1] = l / 2\n    z4[:, 2] = z_vector\n    z4[:, 3] = i\n    w1 = np.zeros(shape=(point_num, 4))\n    w1[:, 0]=w_vector\n    w1[:, 1]=-l / 2\n    w1[:, 2]=-h / 2\n    w1[:, 3] = i\n    w2 = np.zeros(shape=(point_num, 4))\n    w2[:, 0] = w_vector\n    w2[:, 1] = -l/ 2\n    w2[:, 2] = h / 2\n    w2[:, 3] = i\n    w3 = np.zeros(shape=(point_num, 4))\n    w3[:, 0] = w_vector\n    w3[:, 1] = l / 2\n    w3[:, 2] = -h / 2\n    w3[:, 3] = i\n    w4 = np.zeros(shape=(point_num, 4))\n    w4[:, 0] = w_vector\n    w4[:, 1] =l / 2\n    w4[:, 2] = h / 2\n    w4[:, 3] = i\n    l1 = np.zeros(shape=(point_num, 4))\n    l1[:, 0] = -w / 2\n    l1[:, 1] = l_vector\n    l1[:, 2] = -h / 2\n    l1[:, 3] = i\n    l2 = np.zeros(shape=(point_num, 4))\n    l2[:, 0] = -w / 2\n    l2[:, 1] = l_vector\n    l2[:, 2] = h / 2\n    l2[:, 3] = i\n    l3 = np.zeros(shape=(point_num, 4))\n    l3[:, 0] = w / 2\n    l3[:, 1] = l_vector\n    l3[:, 2] = -h / 2\n    l3[:, 3] = i\n    l4 = np.zeros(shape=(point_num, 4))\n    l4[:, 0] = w / 2\n    l4[:, 1] = l_vector\n    l4[:, 2] = h / 2\n    l4[:, 3] = i\n\n    point_mat=np.mat(np.concatenate((z1,z2,z3,z4,w1,w2,w3,w4,l1,l2,l3,l4,d1,d2,d3,d4)))#\n\n    angle=point[6]-PI/2\n\n    if pose is None:\n        convert_mat = np.mat([[math.cos(angle), -math.sin(angle), 0, x],\n                              [math.sin(angle), math.cos(angle), 0, y],\n                              [0, 0, 1, z],\n                              [0, 0, 0, label]])\n\n        transformed_mat = convert_mat * point_mat.T\n    else:\n\n        convert_mat = np.mat([[math.cos(angle), -math.sin(angle), 0, 0],\n                              [math.sin(angle), math.cos(angle), 0, 0],\n                              [0, 0, 1, 0],\n                              [0, 0, 0, 1]])\n        transformed_mat = convert_mat * point_mat.T\n        pose_mat = np.mat([[pose[0, 0], pose[0, 1], pose[0, 2], x],\n                           [pose[1, 0], pose[1, 1], pose[1, 2], y],\n                           [pose[2, 0], pose[2, 1], pose[2, 2], z],\n                           [0, 0, 0, label]])\n        transformed_mat = pose_mat * transformed_mat\n\n\n    transformed_mat = np.array(transformed_mat.T,dtype=np.float32)\n\n    return transformed_mat","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:25.296498Z","iopub.execute_input":"2024-03-23T22:02:25.296801Z","iopub.status.idle":"2024-03-23T22:02:25.366604Z","shell.execute_reply.started":"2024-03-23T22:02:25.296756Z","shell.execute_reply":"2024-03-23T22:02:25.365435Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"## Color Map","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Function to generate random colors based on color map\n# Input: color map name\n# Output: List of random colors\ndef generate_objects_color_map(color_map_name='rainbow'):\n    color_map = []\n    np.random.seed(4)\n\n    x = 0\n    for i in range(10000):\n        if x > 1:\n            x = np.random.random() * 0.5\n        color_map.append(x)\n        x += 0.2\n    cmp = plt.get_cmap(color_map_name)\n    color_map = cmp(color_map)\n    color_map = color_map[:, 0:3] * 255\n    color_map = color_map.astype(np.int).tolist()\n    return color_map\n\n# Function to map object indices to colors\n# Input: Object indices array\n# Input: Colors to select from\n# Output: Color list\ndef generate_objects_colors(object_ids,color_map_list):\n    assert len(color_map_list)>len(object_ids), \"the color map list must longer than object indices list !\"\n\n    if len(object_ids)==0:\n        return []\n    else:\n        colors=[]\n        for i in object_ids:\n            colors.append(color_map_list[i])\n        return colors\n    \n\n# Function to map scatter to colors\n# Input: Scatter points array\n# Input: Colors to select from\n# Output: Color list\ndef generate_scatter_colors(scatters,color_map_name='rainbow'):\n    \"\"\"\n    map the scatters to colors\n    :param scatters: (array or list(N,)),\n    :param color_map_name: (str), the name of objects color map, such as \"rainbow\", \"viridis\",\"brg\",\"gnuplot\",\"hsv\"\n                             reference  https://matplotlib.org/stable/tutorials/colors/colormaps.html\n    :return: (array(N,4)), each item represents (red, green, blue, alpha),\n    \"\"\"\n    if len(scatters)==0:\n        return []\n    else:\n        scatters = np.array(scatters)\n        scatters_max = scatters.max()\n        scatters_min = scatters.min()\n\n        div = scatters_max-scatters_min\n        if div !=0:\n            scatters = (scatters-scatters_min)/div\n        cmp = plt.get_cmap(color_map_name)\n        new_colors = cmp(scatters)\n        new_colors = new_colors[:, 0:3] * 255\n        alpha = np.ones(shape=(len(new_colors), 1)) * 255\n        new_colors = np.concatenate([new_colors, alpha], -1)\n        \n    return new_colors.astype(np.int)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:25.368554Z","iopub.execute_input":"2024-03-23T22:02:25.368922Z","iopub.status.idle":"2024-03-23T22:02:25.382454Z","shell.execute_reply.started":"2024-03-23T22:02:25.368875Z","shell.execute_reply":"2024-03-23T22:02:25.381807Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Viewer Class","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom vedo import *\nimport cv2\nimport vtk\n# test\n# from .color_map import generate_objects_color_map,generate_objects_colors,generate_scatter_colors\n# from .box_op import convert_box_type,get_line_boxes,get_mesh_boxes,velo_to_cam,get_box_points\n\n\n# Viewer Class containing all visualization functions\nclass Viewer:\n    # Initialization Function\n    # OpenPCDet: (x, y, z, l, w, h, yaw)\n    def __init__(self,box_type = \"OpenPCDet\",bg=(255, 255, 255)):\n        self.objects_color_map = generate_objects_color_map('rainbow')\n        self.box_type = box_type\n        self.vi = Plotter(bg=bg)\n        self.set_lights()\n\n        # data for rendering in 3D scene\n        self.actors = []\n        self.actors_without_del = []\n        self.tracks_actors_dict = {}\n\n        # data for rendering in 2D scene\n        self.cam_intrinsic_mat = None\n        self.cam_extrinsic_mat = None\n        self.boxes_info = [] # (boxes:array(N,7), ids:array(N,), colors:array(N,3) or str, box_info:list(N,))\n        self.points_info = [] # (boxes:array(N,3), colors:array(N,3) or str)\n        self.image = None\n\n    # Function to set lighting for vedo visualization\n    def set_lights(self):\n        def get_light(pos=(0, 0, 0), focalPoint=(0, 0, 0)):\n            light = vtk.vtkLight()\n\n            light.SetPosition(pos)\n            light.SetFocalPoint(focalPoint)\n            light.SetIntensity(0.65)\n\n            return light\n\n        light_actors = []\n\n        light_actors.append(get_light(pos=(400, 400, 100), focalPoint=(0, 0, 0)))\n        light_actors.append(get_light(pos=(-400, 400, 100), focalPoint=(0, 0, 0)))\n        light_actors.append(get_light(pos=(400, -400, 100), focalPoint=(0, 0, 0)))\n        light_actors.append(get_light(pos=(-400, -400, 100), focalPoint=(0, 0, 0)))\n        for a in light_actors:\n            self.vi.renderer.AddLight(a)\n\n\n    # Function to set objects colors map\n    # Returns a list of random colors\n    def set_ob_color_map(self,color_map_name='rainbow'):\n        self.objects_color_map = generate_objects_color_map(color_map_name)\n        return self.objects_color_map\n\n    # Function to load ego car model\n    def set_ego_car(self,ego_car_path = \"./ego_car.3ds\"):\n        ego_car = load(ego_car_path)\n        ego_car.pos(-0.5, 0, -1.6)\n        ego_car.scale(0.9)\n        self.actors_without_del+=[ego_car]\n\n    # Function to set intrinsic camera matrix\n    def set_intrinsic_mat(self,intrinsic_mat):\n        self.cam_intrinsic_mat = intrinsic_mat\n\n    # Function to set extrinsic camera matrix\n    def set_extrinsic_mat(self,extrinsic_mat):\n        self.cam_extrinsic_mat = extrinsic_mat\n\n    # Function to add points to visualization\n    def add_points(self,points,\n                   radius = 2,\n                   color = (150,150,150),\n                   scatter_filed=None,\n                   alpha=1,\n                   del_after_show='True',\n                   add_to_3D_scene = True,\n                   add_to_2D_scene = True,\n                   color_map_name = \"rainbow\"):\n        if scatter_filed is not None:\n            # causing error of value of color not supported\n            colors = generate_scatter_colors(scatter_filed,color_map_name=color_map_name)\n        else:\n            colors = color\n\n        if add_to_2D_scene:\n            self.points_info.append((points,colors))\n\n        if add_to_3D_scene:\n            if del_after_show:\n                self.actors.append(Points(points,r=radius,c=colors,alpha=alpha))\n            else:\n                self.actors_without_del.append(Points(points,r=radius,c=colors,alpha=alpha))\n\n    # Function to add sphere to visualization\n    def add_spheres(self,points,\n                    radius = 0.3,\n                    color='red',\n                    res=30,\n                    scatter_filed=None,\n                    alpha=0.5,\n                    del_after_show='True'):\n        if scatter_filed is not None:\n            colors = generate_scatter_colors(scatter_filed)[:,:3]\n        else:\n            colors = color\n\n        if del_after_show:\n            self.actors.append(Spheres(points,r=radius,res=res,c=colors,alpha=alpha))\n        else:\n            self.actors_without_del.append(Spheres(Points,r=radius,res=res,c=colors,alpha=alpha))\n\n    # Function to add 3D Boxes to visualization\n    def add_3D_boxes(self,boxes=None,\n                     ids=None,\n                     box_info=None,\n                     color=\"blue\",\n                     add_to_3D_scene=True,\n                     mesh_alpha = 0,\n                     show_corner_spheres = True,\n                     corner_spheres_alpha = 1,\n                     corner_spheres_radius=0.1,\n                     show_heading = True,\n                     heading_scale = 1,\n                     show_lines = True,\n                     line_width = 2,\n                     line_alpha = 1,\n                     show_ids = True,\n                     show_box_info=True,\n                     del_after_show=True,\n                     add_to_2D_scene=True,\n                     caption_size=(0.05,0.05)\n                     ):\n        if boxes is None:\n            return\n        boxes= convert_box_type(boxes,self.box_type)\n        if boxes is None:\n            return\n\n        if ids is not None:\n            colors = generate_objects_colors(ids,self.objects_color_map)\n        else:\n            colors = color\n\n        if add_to_2D_scene:\n            self.boxes_info.append((boxes,ids,colors,box_info))\n\n        if add_to_3D_scene:\n            if del_after_show:\n                self.actors += get_mesh_boxes(boxes,\n                                              colors,\n                                              mesh_alpha,\n                                              ids,\n                                              show_ids,\n                                              box_info,\n                                              show_box_info,\n                                              caption_size)\n                self.actors += get_line_boxes(boxes,\n                                              colors,\n                                              show_corner_spheres,\n                                              corner_spheres_alpha,\n                                              corner_spheres_radius,\n                                              show_heading,\n                                              heading_scale,\n                                              show_lines,\n                                              line_width,\n                                              line_alpha)\n            else:\n                self.actors_without_del += get_mesh_boxes(boxes,\n                                                          colors,\n                                                          mesh_alpha,\n                                                          ids,\n                                                          show_ids,\n                                                          box_info,\n                                                          show_box_info,\n                                                          caption_size)\n                self.actors_without_del += get_line_boxes(boxes,\n                                                          colors,\n                                                          show_corner_spheres,\n                                                          corner_spheres_alpha,\n                                                          corner_spheres_radius,\n                                                          show_heading,\n                                                          heading_scale,\n                                                          show_lines,\n                                                          line_width,\n                                                          line_alpha)\n\n    # Function to add 3D car objects to visualization\n    def add_3D_cars(self,boxes=None,\n                     ids=None,\n                     box_info=None,\n                     color=\"blue\",\n                     mesh_alpha = 0.1,\n                     show_ids = False,\n                     show_box_info=False,\n                     del_after_show=True,\n                     car_model_path=\"./car.obj\",\n                     caption_size = (0.1, 0.1)\n                    ):\n\n        if boxes is None:\n            return\n        \n        boxes= convert_box_type(boxes,self.box_type)\n        if boxes is None:\n            return\n\n        if ids is not None:\n            colors = generate_objects_colors(ids,self.objects_color_map)\n        else:\n            colors = color\n\n        for i in range(len(boxes)):\n            bb = boxes[i]\n            size = bb[3:6]\n\n            ang=bb[6]\n            ang = int(ang / (2 * np.pi) * 360)\n\n            if type(colors) is str:\n                color = colors\n            else:\n                color = colors[i]\n\n            if ids is not None:\n                ob_id = ids[i]\n                if ob_id in self.tracks_actors_dict.keys():\n                    previous_ori=self.tracks_actors_dict[ob_id].GetOrientation()[2]\n                    self.tracks_actors_dict[ob_id].pos(0,0,0)\n                    self.tracks_actors_dict[ob_id].rotateZ(ang-previous_ori)\n                    self.tracks_actors_dict[ob_id].pos(bb[0], bb[1], bb[2])\n\n                    info = \"\"\n                    if ids is not None and show_ids:\n                        info = \"ID: \" + str(ids[i]) + '\\n'\n                    if box_info is not None and show_box_info:\n                        info += str(box_info[i])\n                    if info != '':\n                        self.tracks_actors_dict[ob_id].caption(info,\n                                                               point=(bb[0], bb[1] - bb[4] / 2, bb[2] + bb[5] / 2),\n                                                               size=caption_size,\n                                                               alpha=1,\n                                                               c=color,\n                                                               font=\"Calco\",\n                                                               justify='left')\n                        self.tracks_actors_dict[ob_id]._caption.SetBorder(False)\n                        self.tracks_actors_dict[ob_id]._caption.SetLeader(False)\n\n                    if del_after_show:\n                        self.actors.append(self.tracks_actors_dict[ob_id])\n                    else:\n                        self.actors_without_del.append(self.tracks_actors_dict[ob_id])\n                else:\n\n                    new_car=load(car_model_path)\n                    new_car.scale((0.12,0.3,0.3))\n\n                    new_car.scale(size)\n                    new_car.rotateZ(ang)\n                    new_car.pos(bb[0], bb[1], bb[2])\n\n                    new_car.c(color)\n                    new_car.alpha(mesh_alpha)\n                    self.tracks_actors_dict[ob_id]=new_car\n                    info = \"\"\n                    if ids is not None and show_ids:\n                        info = \"ID: \" + str(ids[i]) + '\\n'\n                    if box_info is not None and show_box_info:\n                        info += str(box_info[i])\n                    if info != '':\n                        self.tracks_actors_dict[ob_id].caption(info,\n                                                               point=(bb[0], bb[1] - bb[4] / 2, bb[2] + bb[5] / 2),\n                                                               size=caption_size,\n                                                               alpha=1,\n                                                               c=color,\n                                                               font=\"Calco\",\n                                                               justify='left')\n                        self.tracks_actors_dict[ob_id]._caption.SetBorder(False)\n                        self.tracks_actors_dict[ob_id]._caption.SetLeader(False)\n\n                    if del_after_show:\n                        self.actors.append(self.tracks_actors_dict[ob_id])\n                    else:\n                        self.actors_without_del.append(self.tracks_actors_dict[ob_id])\n\n            else:\n                new_car = load(car_model_path)\n                new_car.scale((0.12, 0.3, 0.3))\n\n                new_car.scale(size)\n                new_car.rotateZ(ang)\n                new_car.pos(bb[0], bb[1], bb[2])\n\n                new_car.c(color)\n                new_car.alpha(mesh_alpha)\n\n                info = \"\"\n\n                if box_info is not None and show_box_info:\n                    info += str(box_info[i])\n                if info != '':\n                    new_car.caption(info,\n                                   point=(bb[0], bb[1] - bb[4] / 2, bb[2] + bb[5] / 2),\n                                   size=caption_size,\n                                   alpha=1,\n                                   c=color,\n                                   font=\"Calco\",\n                                   justify='cent')\n                    new_car._caption.SetBorder(False)\n                    new_car._caption.SetLeader(False)\n                if del_after_show:\n                    self.actors.append(new_car)\n                else:\n                    self.actors_without_del.append(new_car)\n\n    # Function to add image to visualzation\n    def add_image(self,im):\n        self.image = im\n        return\n\n    # Function to show 3D scene visualization\n    def show_3D(self):\n        self.vi.show(self.actors+self.actors_without_del,resetcam=False)\n        self.vi.clear()\n        self.actors.clear()\n        self.points_info.clear()\n        self.boxes_info.clear()\n\n    # Function to show 2D scene visualization\n    def show_2D(self,box_color = (255,0,0),show_box_info=False,show_ids=True,points_colors=(0,0,255)):\n        if (self.cam_extrinsic_mat is None) or (self.cam_intrinsic_mat is None) or (self.image is None):\n            return\n\n        H,W,_ = self.image.shape\n\n        for info in self.boxes_info:\n            boxes, ids, colors, box_info=info\n\n            if boxes is None:\n                continue\n            elif len(boxes) == 0:\n                continue\n            else:\n\n                for box_id in range(len(boxes)):\n                    box = boxes[box_id]\n                    if type(colors) is not str:\n                        color = [colors[box_id][2],colors[box_id][1],colors[box_id][0]]\n                    else:\n                        color = box_color\n\n                    pts_3d_cam = get_box_points(box)\n                    pts_3d_cam = velo_to_cam(pts_3d_cam[:,0:3],self.cam_extrinsic_mat)\n\n                    img_pts = np.matmul(pts_3d_cam, self.cam_intrinsic_mat.T)  # (N, 3)\n                    x, y = img_pts[:, 0] / img_pts[:, 2], img_pts[:, 1] / img_pts[:, 2]\n\n                    x = np.clip(x, 2, W-2)\n                    y = np.clip(y, 2, H-2)\n\n                    x = x.astype(np.int)\n                    y = y.astype(np.int)\n\n                    self.image[y, x] = color\n\n                    x2 = x + 1\n                    self.image[y, x2] = color\n                    y2 = y + 1\n                    self.image[y2, x] = color\n                    self.image[y2, x2] = color\n\n                    info = \"\"\n                    if ids is not None and show_ids:\n                        info +=  str(ids[box_id])+\" \"\n                    if box_info is not None and show_box_info:\n                        info += str(box_info[box_id])\n\n                    if info != '':\n\n                        text = info\n                        org = ((max(x) - min(x)) // 2 + min(x), min(y) - 5)\n                        fontFace = cv2.FONT_HERSHEY_DUPLEX\n                        fontScale = 0.7\n                        fontcolor = color  # BGR\n                        thickness = 1\n                        lineType = 4\n                        cv2.putText(self.image, text, org, fontFace, fontScale, fontcolor, thickness, lineType)\n\n        for points,colors in self.points_info:\n\n            if type(colors) is tuple:\n\n                color = [colors[2],colors[1],colors[0]]\n            else:\n                color = points_colors\n\n            pts_3d_cam = velo_to_cam(points[:, 0:3], self.cam_extrinsic_mat)\n\n            img_pts = np.matmul(pts_3d_cam, self.cam_intrinsic_mat.T)  # (N, 3)\n            x, y = img_pts[:, 0] / img_pts[:, 2], img_pts[:, 1] / img_pts[:, 2]\n\n            x = np.clip(x, 2, W - 2)\n            y = np.clip(y, 2, H - 2)\n\n            x = x.astype(np.int)\n            y = y.astype(np.int)\n\n            self.image[y, x] = color\n\n        cv2.imshow('im',self.image)\n        cv2.waitKey(10)\n        self.points_info.clear()\n        self.boxes_info.clear()\n        \n    # Function to save 2D visualization\n    def save_2D(self, image_file, box_color = (255,0,0),show_box_info=False,show_ids=True,points_colors=(0,0,255)):\n        if (self.cam_extrinsic_mat is None) or (self.cam_intrinsic_mat is None) or (self.image is None):\n            return\n\n        H,W,_ = self.image.shape\n\n        for info in self.boxes_info:\n            boxes, ids, colors, box_info=info\n\n            if boxes is None:\n                continue\n            elif len(boxes) == 0:\n                continue\n            else:\n\n                for box_id in range(len(boxes)):\n                    box = boxes[box_id]\n                    if type(colors) is not str:\n                        color = [colors[box_id][2],colors[box_id][1],colors[box_id][0]]\n                    else:\n                        color = box_color\n\n                    pts_3d_cam = get_box_points(box)\n                    pts_3d_cam = velo_to_cam(pts_3d_cam[:,0:3],self.cam_extrinsic_mat)\n\n                    img_pts = np.matmul(pts_3d_cam, self.cam_intrinsic_mat.T)  # (N, 3)\n                    x, y = img_pts[:, 0] / img_pts[:, 2], img_pts[:, 1] / img_pts[:, 2]\n\n                    x = np.clip(x, 2, W-2)\n                    y = np.clip(y, 2, H-2)\n\n                    x = x.astype(np.int)\n                    y = y.astype(np.int)\n\n                    self.image[y, x] = color\n\n                    x2 = x + 1\n                    self.image[y, x2] = color\n                    y2 = y + 1\n                    self.image[y2, x] = color\n                    self.image[y2, x2] = color\n\n                    info = \"\"\n                    if ids is not None and show_ids:\n                        info +=  str(ids[box_id])+\" \"\n                    if box_info is not None and show_box_info:\n                        info += str(box_info[box_id])\n\n                    if info != '':\n\n                        text = info\n                        org = ((max(x) - min(x)) // 2 + min(x), min(y) - 5)\n                        fontFace = cv2.FONT_HERSHEY_DUPLEX\n                        fontScale = 0.7\n                        fontcolor = color  # BGR\n                        thickness = 1\n                        lineType = 4\n                        cv2.putText(self.image, text, org, fontFace, fontScale, fontcolor, thickness, lineType)\n\n        for points,colors in self.points_info:\n            if isinstance(colors,(list,tuple,np.ndarray)):\n                color = []\n                for c in colors:\n                    color.append([c[2], c[1], c[0]])\n            else:\n                color = points_colors\n\n            pts_3d_cam = velo_to_cam(points[:, 0:3], self.cam_extrinsic_mat)\n\n            img_pts = np.matmul(pts_3d_cam, self.cam_intrinsic_mat.T)  # (N, 3)\n            x, y = img_pts[:, 0] / img_pts[:, 2], img_pts[:, 1] / img_pts[:, 2]\n\n            x = np.clip(x, 2, W - 2)\n            y = np.clip(y, 2, H - 2)\n\n            x = x.astype(np.int)\n            y = y.astype(np.int)\n            \n            self.image[y, x] = color\n\n        print(f\"Saving Image: {image_file}\")\n        cv2.imwrite(image_file, self.image)\n        self.points_info.clear()\n        self.boxes_info.clear()\n        \n    # Function to create birds eye view of lidar\n    def birds_eye_view(self, image_file, box_color = (255,0,0),show_box_info=False,\n                       show_ids=True,points_colors=(0,0,255)):\n        if (self.cam_extrinsic_mat is None) or (self.cam_intrinsic_mat is None) or (self.image is None):\n            return\n\n        H,W,_ = self.image.shape\n\n        for info in self.boxes_info:\n            boxes, ids, colors, box_info=info\n\n            if boxes is None:\n                continue\n            elif len(boxes) == 0:\n                continue\n            else:\n\n                for box_id in range(len(boxes)):\n                    box = boxes[box_id]\n                    if type(colors) is not str:\n                        color = [colors[box_id][2],colors[box_id][1],colors[box_id][0]]\n                    else:\n                        color = box_color\n\n                    pts_3d_cam = get_box_points(box)\n#                     pts_3d_cam = velo_to_cam(pts_3d_cam[:,0:3], self.cam_extrinsic_mat)\n                    \n                    # Extract points\n                    x_points = pts_3d_cam[:, 0]\n                    y_points = pts_3d_cam[:, 1]\n                    z_points = pts_3d_cam[:, 2]\n\n                    # Convert to pixel positions\n                    x_img = x_points\n                    y_img = y_points\n\n                    x_img = (x_img - np.min(x_img)) * W / np.ptp(x_img)\n                    y_img = (y_img - np.min(y_img)) * H / np.ptp(y_img)\n\n                    # FILL PIXEL VALUES IN IMAGE ARRAY\n                    x_img = np.clip(x_img, 2, W - 2)\n                    y_img = np.clip(y_img, 2, H - 2)\n\n                    x = x_img.astype(np.int)\n                    y = y_img.astype(np.int)\n\n                    self.image[y, x] = color\n\n#                     x2 = x + 1\n#                     self.image[y, x2] = color\n#                     y2 = y + 1\n#                     self.image[y2, x] = color\n#                     self.image[y2, x2] = color\n\n                    info = \"\"\n                    if ids is not None and show_ids:\n                        info +=  str(ids[box_id])+\" \"\n                    if box_info is not None and show_box_info:\n                        info += str(box_info[box_id])\n\n                    if info != '':\n\n                        text = info\n                        org = ((max(x) - min(x)) // 2 + min(x), min(y) - 5)\n                        fontFace = cv2.FONT_HERSHEY_DUPLEX\n                        fontScale = 0.7\n                        fontcolor = color  # BGR\n                        thickness = 1\n                        lineType = 4\n                        cv2.putText(self.image, text, org, fontFace, fontScale, fontcolor, thickness, lineType)\n\n        for points,colors in self.points_info:\n            if isinstance(colors,(list,tuple,np.ndarray)):\n                color = []\n                for c in colors:\n                    color.append([c[2], c[1], c[0]])\n            else:\n                color = points_colors\n                \n            pts_3d_cam = points\n                            \n            # Extract points\n            x_points = pts_3d_cam[:, 0]\n            y_points = pts_3d_cam[:, 1]\n            z_points = pts_3d_cam[:, 2]\n\n            # Convert to pixel positions\n            x_img = x_points\n            y_img = y_points\n            \n            x_img = (x_img - np.min(x_img)) * W / np.ptp(x_img)\n            y_img = (y_img - np.min(y_img)) * H / np.ptp(y_img)\n\n            # FILL PIXEL VALUES IN IMAGE ARRAY\n            x_img = np.clip(x_img, 2, W - 2)\n            y_img = np.clip(y_img, 2, H - 2)\n\n            x_img = x_img.astype(np.int)\n            y_img = y_img.astype(np.int)\n            self.image[y_img, x_img] = color\n\n        print(f\"Saving Image: {image_file}\")\n        cv2.imwrite(image_file, self.image)\n        self.points_info.clear()\n        self.boxes_info.clear()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:25.385481Z","iopub.execute_input":"2024-03-23T22:02:25.386272Z","iopub.status.idle":"2024-03-23T22:02:25.480779Z","shell.execute_reply.started":"2024-03-23T22:02:25.386233Z","shell.execute_reply":"2024-03-23T22:02:25.480028Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# Visualize\nCombine all the code developed above","metadata":{}},{"cell_type":"code","source":"root = '../input/kitti-3d-object-detection-dataset/training'\nlabel_path = '../input/kitti-3d-object-detection-dataset/training/label_2'\n\ndataset = KittiDetectionDataset(root, label_path)\n\nvi = Viewer(box_type = \"Kitti\")\nvi.set_ob_color_map('gnuplot')\n\ndef visualize_points(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    black_image = np.zeros_like(image)\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(black_image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.add_points(points[:,0:3], radius = 1000, color = (\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255)),\n                  scatter_filed = points[:,2], alpha=0, del_after_show = True,\n                  add_to_3D_scene = True, add_to_2D_scene = True,\n                  color_map_name = \"viridis\")\n#                   color_map_name = \"cool\")\n    vi.save_2D(f\"point_image_{index}.png\")\n    \ndef visualize_bev(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    black_image = np.zeros_like(image)\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(black_image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.add_points(points[:,0:3], radius = 1000, color = (\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255)),\n                  scatter_filed = points[:,2], alpha=0, del_after_show = True,\n                  add_to_3D_scene = True, add_to_2D_scene = True,\n                  color_map_name = \"cool\")\n    vi.birds_eye_view(f\"bev_image_{index}.png\")\n    \n# TODO\ndef visualize_bev_box(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    black_image = np.zeros_like(image)\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(black_image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.add_points(points[:,0:3], radius = 1000, color = (\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255)),\n                  scatter_filed = points[:,2], alpha=0, del_after_show = True,\n                  add_to_3D_scene = True, add_to_2D_scene = True,\n                  color_map_name = \"cool\")\n    vi.add_3D_boxes(boxes=labels, ids=ids, box_info=label_names,\n                 color= (0, 0, 255), # blue color\n                 add_to_3D_scene=True, add_to_2D_scene = True,\n                 mesh_alpha = 0.3, show_corner_spheres = True, corner_spheres_alpha = 1,\n                 corner_spheres_radius=0.1, show_heading = True, heading_scale = 1,\n                 show_lines = True, line_width = 2, line_alpha = 1, show_ids = True,\n                 show_box_info=True, del_after_show=True, caption_size=(0.05,0.05))\n    \n    vi.birds_eye_view(f\"bev_image_{index}.png\")\n    \ndef visualize_image(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    black_image = np.zeros_like(image)\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.save_2D(f\"image_{index}.png\")\n    \ndef visualize_image_box(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    black_image = np.zeros_like(image)\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.add_3D_boxes(boxes=labels, ids=ids, box_info=label_names,\n                 color=\"blue\", add_to_3D_scene=True, add_to_2D_scene = True,\n                 mesh_alpha = 0.3, show_corner_spheres = True, corner_spheres_alpha = 1,\n                 corner_spheres_radius=0.1, show_heading = True, heading_scale = 1,\n                 show_lines = True, line_width = 2, line_alpha = 1, show_ids = True,\n                 show_box_info=True, del_after_show=True, caption_size=(0.05,0.05))\n    vi.save_2D(f\"image_box_{index}.png\")\n\ndef visualize(index):\n    P2, V2C, points, image, labels, label_names = dataset[index]\n    white_image = np.ones_like(image) * 255\n    \n    mask = label_names==\"Car\"\n    labels = labels[mask]\n    label_names = label_names[mask]\n    ids = labels[:, -1].astype(int)\n    \n    vi.add_image(white_image)\n    vi.set_extrinsic_mat(V2C)\n    vi.set_intrinsic_mat(P2)\n    vi.add_points(points[:,0:3], radius = 2, color = (\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255),\"{:.1f}\".format(150/255)),\n                  scatter_filed = points[:,2], alpha=0, del_after_show = True,\n                  add_to_3D_scene = True, add_to_2D_scene = True,\n                  color_map_name = \"viridis\")\n    \n    vi.add_3D_boxes(boxes=labels, ids=ids, box_info=label_names,\n                 color=\"blue\", add_to_3D_scene=True, add_to_2D_scene = True,\n                 mesh_alpha = 0.3, show_corner_spheres = True, corner_spheres_alpha = 1,\n                 corner_spheres_radius=0.1, show_heading = True, heading_scale = 1,\n                 show_lines = True, line_width = 2, line_alpha = 1, show_ids = True,\n                 show_box_info=True, del_after_show=True, caption_size=(0.05,0.05))\n    \n    vi.save_2D(f'image_full_{index}.png')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:25.482171Z","iopub.execute_input":"2024-03-23T22:02:25.482407Z","iopub.status.idle":"2024-03-23T22:02:25.685118Z","shell.execute_reply.started":"2024-03-23T22:02:25.482379Z","shell.execute_reply":"2024-03-23T22:02:25.683923Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"import random\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nindex_list = random.sample(range(len(dataset)), 5)\nimages = []\nfor index in index_list:\n    visualize_points(index)\n    images.append(mpimg.imread(f\"point_image_{index}.png\"))\n    \nfor image in images:\n    plt.figure(figsize=(30, 30), dpi=80)\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:25.686862Z","iopub.execute_input":"2024-03-23T22:02:25.687158Z","iopub.status.idle":"2024-03-23T22:02:26.230789Z","shell.execute_reply.started":"2024-03-23T22:02:25.687121Z","shell.execute_reply":"2024-03-23T22:02:26.229337Z"},"trusted":true},"execution_count":71,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/3405521345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvisualize_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"point_image_{index}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_20/181511438.py\u001b[0m in \u001b[0;36mvisualize_points\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mscatter_filed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_after_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                   \u001b[0madd_to_3D_scene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_to_2D_scene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                   color_map_name = \"viridis\")\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#                   color_map_name = \"cool\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"point_image_{index}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_20/2303393296.py\u001b[0m in \u001b[0;36madd_points\u001b[0;34m(self, points, radius, color, scatter_filed, alpha, del_after_show, add_to_3D_scene, add_to_2D_scene, color_map_name)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_3D_scene\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdel_after_show\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors_without_del\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/vedo/pointcloud.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputobj, r, c, alpha)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetInputData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOpacity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetRepresentationToPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: SetColor argument 1: expected a sequence of 3 values, got 20123 values"],"ename":"TypeError","evalue":"SetColor argument 1: expected a sequence of 3 values, got 20123 values","output_type":"error"}]},{"cell_type":"code","source":"images = []\nfor index in index_list:\n    visualize_bev(index)\n    images.append(mpimg.imread(f\"bev_image_{index}.png\"))\n    \nfor image in images:\n    plt.figure(figsize=(30, 30), dpi=80)\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:26.232003Z","iopub.status.idle":"2024-03-23T22:02:26.232669Z","shell.execute_reply.started":"2024-03-23T22:02:26.232363Z","shell.execute_reply":"2024-03-23T22:02:26.232394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nfor index in index_list:\n    visualize_image(index)\n    images.append(mpimg.imread(f\"image_{index}.png\"))\n    \nfor image in images:\n    plt.figure(figsize=(30, 30), dpi=80)\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:26.234242Z","iopub.status.idle":"2024-03-23T22:02:26.234942Z","shell.execute_reply.started":"2024-03-23T22:02:26.234659Z","shell.execute_reply":"2024-03-23T22:02:26.234690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nfor index in index_list:\n    visualize_image_box(index)\n    images.append(mpimg.imread(f\"image_box_{index}.png\"))\n    \nfor image in images:\n    plt.figure(figsize=(30, 30), dpi=80)\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:26.236334Z","iopub.status.idle":"2024-03-23T22:02:26.236809Z","shell.execute_reply.started":"2024-03-23T22:02:26.236539Z","shell.execute_reply":"2024-03-23T22:02:26.236564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nfor index in index_list:\n    visualize(index)\n    images.append(mpimg.imread(f\"image_full_{index}.png\"))\n    \nfor image in images:\n    plt.figure(figsize=(30, 30), dpi=80)\n    plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:26.238449Z","iopub.status.idle":"2024-03-23T22:02:26.239071Z","shell.execute_reply.started":"2024-03-23T22:02:26.238794Z","shell.execute_reply":"2024-03-23T22:02:26.238824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}